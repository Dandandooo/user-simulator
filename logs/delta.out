Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Running unsloth/llama-3-8b-bnb-4bit on cuda:1
Answering "zero" dataset
Answering a2517febe5770439_0513 (1/181)
<class 'str'>
Traceback (most recent call last):
  File "/projects/bckf/dphilipov/teach-recreate/src/prompt_llm/runllama.py", line 11, in <module>
    llama3.save_answers("zero", "llm_prompt_sessions/llama_no-train/zero_no_move/")
  File "/projects/bckf/dphilipov/teach-recreate/src/model/causal.py", line 73, in save_answers
    for file_id, answered_folder in self.answer_dataset(dataset_name):
  File "/projects/bckf/dphilipov/teach-recreate/src/model/causal.py", line 69, in answer_dataset
    responses.append((file_id, list(self.answer_folder(folder))))
TypeError: 'NoneType' object is not iterable
